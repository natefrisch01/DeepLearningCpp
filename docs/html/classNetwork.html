<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>DeepLearningC++: Network Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DeepLearningC++
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classNetwork-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Network Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Stores a Neural network and implements methods for performing stochastic gradient descent.  
 <a href="classNetwork.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="network_8h_source.html">network.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aa6382995a4a0bc915d12d794eb584adf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#aa6382995a4a0bc915d12d794eb584adf">Network</a> (std::vector&lt; int &gt; &amp;sizes)</td></tr>
<tr class="separator:aa6382995a4a0bc915d12d794eb584adf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fba84f6e70a7c89fff90091efd51679"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a4fba84f6e70a7c89fff90091efd51679">feedForward</a> (Eigen::VectorXd &amp;input)</td></tr>
<tr class="separator:a4fba84f6e70a7c89fff90091efd51679"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdb38726769a9f571f09a5f10f6b6847"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#acdb38726769a9f571f09a5f10f6b6847">SGD</a> (std::vector&lt; sample &gt; &amp;training_data, int epochs, int mini_batch_size, int eta, std::vector&lt; sample &gt; &amp;test_data)</td></tr>
<tr class="separator:acdb38726769a9f571f09a5f10f6b6847"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af736bbf264f09be714d5961ef670a5cb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#af736bbf264f09be714d5961ef670a5cb">update_mini_batch</a> (std::vector&lt; sample &gt; &amp;mini_batch, int eta)</td></tr>
<tr class="separator:af736bbf264f09be714d5961ef670a5cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a657a8db0aad5e948118f188b19d8584c"><td class="memItemLeft" align="right" valign="top">std::pair&lt; bias_list, weight_list &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a657a8db0aad5e948118f188b19d8584c">backprop</a> (Eigen::VectorXd &amp;in, Eigen::VectorXd &amp;desired_out)</td></tr>
<tr class="separator:a657a8db0aad5e948118f188b19d8584c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a062ac4352c92fc2bd88b51bbc29c25a4"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a062ac4352c92fc2bd88b51bbc29c25a4">evaluate</a> (std::vector&lt; sample &gt; test_data)</td></tr>
<tr class="separator:a062ac4352c92fc2bd88b51bbc29c25a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a108865a0ac7351810451cf9ee60b57ed"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a108865a0ac7351810451cf9ee60b57ed">cost_derivative</a> (Eigen::VectorXd &amp;output_activations, Eigen::VectorXd &amp;desired_out)</td></tr>
<tr class="separator:a108865a0ac7351810451cf9ee60b57ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d50530a35db77496d47d5662154830a"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a1d50530a35db77496d47d5662154830a">sigmoid</a> (Eigen::VectorXd)</td></tr>
<tr class="separator:a1d50530a35db77496d47d5662154830a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8569e18257ede199f14febf93e44968f"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a8569e18257ede199f14febf93e44968f">sigmoid_prime</a> (Eigen::VectorXd &amp;)</td></tr>
<tr class="separator:a8569e18257ede199f14febf93e44968f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97f385db3fd78d16a73a7f8b2d18f968"><td class="memItemLeft" align="right" valign="top">Eigen::MatrixXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNetwork.html#a97f385db3fd78d16a73a7f8b2d18f968">colvec_dot_rowvec</a> (Eigen::VectorXd col, Eigen::VectorXd row)</td></tr>
<tr class="separator:a97f385db3fd78d16a73a7f8b2d18f968"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Stores a Neural network and implements methods for performing stochastic gradient descent. </p>
<p>This class is a cpp adaptation of the first two chapters in MichealNielsen's book on neural networks and deep learning, found at <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a>. It stores a neural network as a vector of vectors for biases and a vector of matrices for weights.</p>
<dl class="section author"><dt>Author</dt><dd>Nathanael Frisch </dd></dl>
<dl class="section date"><dt>Date</dt><dd>May 2020 </dd></dl>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aa6382995a4a0bc915d12d794eb584adf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6382995a4a0bc915d12d794eb584adf">&#9670;&nbsp;</a></span>Network()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Network::Network </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>sizes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Initializes the neural network (nn). Accepts a vector of sizes, the first index corresponding to the number of neurons in the input layer, the last index corresponding to the number of neurons in the output layer, and the middle values corresponding to hidden layers.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">sizes</td><td>vector of layer sizes. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a657a8db0aad5e948118f188b19d8584c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a657a8db0aad5e948118f188b19d8584c">&#9670;&nbsp;</a></span>backprop()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt;bias_list, weight_list&gt; Network::backprop </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"><em>desired_out</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>The heart of the nn's ability to learn. It performs gradient descent, starting with the output layer and propogates backwards.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>input layer activation. </td></tr>
    <tr><td class="paramname">desired_out</td><td>desired output. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a pair of a list of biases and a list of weights, the desired nudges to them from this one training example. </dd></dl>

</div>
</div>
<a id="a97f385db3fd78d16a73a7f8b2d18f968"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97f385db3fd78d16a73a7f8b2d18f968">&#9670;&nbsp;</a></span>colvec_dot_rowvec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::MatrixXd Network::colvec_dot_rowvec </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>row</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>This is a weird one, but it's used in backprop. Takes a column vector and a row vector, multiplies each element in the column by each element in the row and, instead of summing, returns a matrix for each individual product.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">col</td><td>column vector. </td></tr>
    <tr><td class="paramname">row</td><td>row vector. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a matrix as described above. </dd></dl>

</div>
</div>
<a id="a108865a0ac7351810451cf9ee60b57ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a108865a0ac7351810451cf9ee60b57ed">&#9670;&nbsp;</a></span>cost_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd Network::cost_derivative </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"><em>output_activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"><em>desired_out</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>The derivative of the cost function. In this case simply simply the actual output activations - the desired output (elementwise).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">output_activations</td><td>actual output activations. </td></tr>
    <tr><td class="paramname">desired_out</td><td>desired output activations. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>derivative of the cost function. </dd></dl>

</div>
</div>
<a id="a062ac4352c92fc2bd88b51bbc29c25a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a062ac4352c92fc2bd88b51bbc29c25a4">&#9670;&nbsp;</a></span>evaluate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Network::evaluate </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; sample &gt;&#160;</td>
          <td class="paramname"><em>test_data</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Feed forward a vector of samples. Return the percentage of samples that it classifies correctly.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">test_data</td><td>vector of samples. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>percentage of samples correctly classified. </dd></dl>

</div>
</div>
<a id="a4fba84f6e70a7c89fff90091efd51679"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4fba84f6e70a7c89fff90091efd51679">&#9670;&nbsp;</a></span>feedForward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd Network::feedForward </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Feeds forward a vector of activations from the first input layer to the output layer, returning a the vector of activations at the output layer. Input vector size must be equal to the number of neurons in the input layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>vector of activations at input layer. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>output activations. </dd></dl>

</div>
</div>
<a id="acdb38726769a9f571f09a5f10f6b6847"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdb38726769a9f571f09a5f10f6b6847">&#9670;&nbsp;</a></span>SGD()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Network::SGD </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; sample &gt; &amp;&#160;</td>
          <td class="paramname"><em>training_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>epochs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mini_batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>eta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; sample &gt; &amp;&#160;</td>
          <td class="paramname"><em>test_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Performs stochastic gradient descent on the nn.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">training_data</td><td>a std::vector of type sample i.e. a list of pairs of input activations and desired output activations. Used for training. </td></tr>
    <tr><td class="paramname">epochs</td><td>number of times to train on the entire dataset. </td></tr>
    <tr><td class="paramname">eta</td><td>learning rate. </td></tr>
    <tr><td class="paramname">test_data</td><td>a std::vector of type sample i.e. a list of pairs of input activations and desired output activations. Used for evaluate. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1d50530a35db77496d47d5662154830a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d50530a35db77496d47d5662154830a">&#9670;&nbsp;</a></span>sigmoid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd Network::sigmoid </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Element-wise squishification btw. 0 and 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector</td><td>to be squished. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>squished vector. </dd></dl>

</div>
</div>
<a id="a8569e18257ede199f14febf93e44968f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8569e18257ede199f14febf93e44968f">&#9670;&nbsp;</a></span>sigmoid_prime()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd Network::sigmoid_prime </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Derivative of squishification function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector</td><td>to be derived. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>derivative of the squish function. </dd></dl>

</div>
</div>
<a id="af736bbf264f09be714d5961ef670a5cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af736bbf264f09be714d5961ef670a5cb">&#9670;&nbsp;</a></span>update_mini_batch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Network::update_mini_batch </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; sample &gt; &amp;&#160;</td>
          <td class="paramname"><em>mini_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>eta</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Performs backprop on each sample from a mini batch of the data (a smaller subset of the full training data), then updates the weights and biases.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mini_batch</td><td>a std::vector of type sample i.e. a list of pairs of input activations and desired output activations.</td></tr>
    <tr><td class="paramname">eta</td><td>learning rate. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/nathanael/tensorflow/DeepLearningCpp/include/<a class="el" href="network_8h_source.html">network.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
